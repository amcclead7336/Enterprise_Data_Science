{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment2\n",
    "## Text Classificiation\n",
    "\n",
    "### Task:\n",
    "Client has requested that we take content from websites and classify them as\n",
    "* business\n",
    "* politics\n",
    "* tech\n",
    "* entertainment\n",
    "* sports\n",
    "\n",
    "### Data:\n",
    "News | Category\n",
    "---- | --------\n",
    "US cyber security chief resigns... | tech\n",
    "Italy 8-38 Wales  Wales secured their first away win in the RBS Six Nations...| sports\n",
    "... | ...\n",
    "\n",
    "\n",
    "## Steps:\n",
    "### Preprocessing\n",
    "Data presented is sparse, content and classification only so no real need for data preprocessing.\n",
    "\n",
    "### Data Evaluation\n",
    "Again, since only content and category are given so not much to go on here. Took data and transformed it with count vectorizer. This gives us  word counts for each word in a matrix.\n",
    "\n",
    "### Model Selection\n",
    "Tested multiple models:\n",
    "* Logistic Regression\n",
    "* K Nearest Neighbors\n",
    "* SVR\n",
    "* KSVR\n",
    "\n",
    "and found Logistic Regression was the best option with 98.38%\n",
    "\n",
    "## Summary:\n",
    "After Vectorization of the data, I found that Logistic Regression tested best with 98.38% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools for data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reading in Data\n",
    "df = pd.read_csv(\"./Assignment2_BBCNewsData.csv\")\n",
    "X = df.iloc[: , 1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mlflow\n",
    "Using Mlflow to save models.\n",
    "\n",
    "To run I used:\n",
    "```powershell\n",
    "mlflow server --backend-store-uri 'C:/temp/mlflow/localserver'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"Assignment2 Experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data and vectorized words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1668x26282 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 339442 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences_train)\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Models:\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Miniconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128   2   1   0   0]\n",
      " [  1 104   0   0   0]\n",
      " [  1   0  91   0   0]\n",
      " [  1   0   0 115   0]\n",
      " [  1   2   0   0 110]]\n",
      "score: 0.9838420107719928\n",
      "Inside MLflow Run with run_id `590f07e8d5414e5a88425aec7f3de393` and experiment_id `1`\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "with mlflow.start_run(run_name=\"Basic LR Experiment\") as run:\n",
    "\n",
    "    log_reg_classifier = LogisticRegression(random_state = 10)\n",
    "    log_reg_classifier.fit(X_train, y_train)\n",
    "    log_reg_y_pred = log_reg_classifier.predict(X_test)\n",
    "\n",
    "    log_reg_cm = confusion_matrix(y_test, log_reg_y_pred)\n",
    "    print(log_reg_cm)\n",
    "    log_reg_score = accuracy_score(y_test, log_reg_y_pred)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(log_reg_classifier, \"LR-model\")\n",
    "\n",
    "    # Create metrics\n",
    "    print(f\"score: {log_reg_score}\")\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"score\", log_reg_score)\n",
    "\n",
    "    runID = run.info.run_uuid\n",
    "    experimentID = run.info.experiment_id\n",
    "\n",
    "    print(f\"Inside MLflow Run with run_id `{runID}` and experiment_id `{experimentID}`\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104   1   4  20   2]\n",
      " [  7  67   4  27   0]\n",
      " [ 12   5  68   5   2]\n",
      " [  7   1   2 106   0]\n",
      " [ 23   6   4  10  70]]\n",
      "score: 0.7450628366247756\n",
      "Inside MLflow Run with run_id `d7f022182d974c7f9c517b3a3bfa4865` and experiment_id `1`\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"Basic KNN Experiment\") as run:\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    knn_y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "    knn_cm = confusion_matrix(y_test, knn_y_pred)\n",
    "    print(knn_cm)\n",
    "    knn_score = accuracy_score(y_test, knn_y_pred)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(knn_classifier, \"KNN-model\")\n",
    "\n",
    "    # Create metrics\n",
    "    print(f\"score: {knn_score}\")\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"score\", knn_score)\n",
    "\n",
    "    runID = run.info.run_uuid\n",
    "    experimentID = run.info.experiment_id\n",
    "\n",
    "    print(f\"Inside MLflow Run with run_id `{runID}` and experiment_id `{experimentID}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[124   4   2   0   1]\n",
      " [  1 104   0   0   0]\n",
      " [  2   0  90   0   0]\n",
      " [  2   0   0 114   0]\n",
      " [  0   2   0   0 111]]\n",
      "score: 0.9748653500897666\n",
      "Inside MLflow Run with run_id `6aba42da8d574d44a9cdb28bda082775` and experiment_id `1`\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "with mlflow.start_run(run_name=\"Basic SVR Experiment\") as run:\n",
    "    svr_classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "    svr_classifier.fit(X_train, y_train)\n",
    "    svr_y_pred = svr_classifier.predict(X_test)\n",
    "\n",
    "    svr_cm = confusion_matrix(y_test, svr_y_pred)\n",
    "    print(svr_cm)\n",
    "    svr_score = accuracy_score(y_test, svr_y_pred)\n",
    "    svr_score\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(svr_classifier, \"SVR-model\")\n",
    "\n",
    "    # Create metrics\n",
    "    print(f\"score: {svr_score}\")\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"score\", svr_score)\n",
    "\n",
    "    runID = run.info.run_uuid\n",
    "    experimentID = run.info.experiment_id\n",
    "\n",
    "    print(f\"Inside MLflow Run with run_id `{runID}` and experiment_id `{experimentID}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[125   2   3   0   1]\n",
      " [  4  97   0   4   0]\n",
      " [  3   0  88   0   1]\n",
      " [  1   0   0 114   1]\n",
      " [  6   0   0   0 107]]\n",
      "score: 0.9533213644524237\n",
      "Inside MLflow Run with run_id `3e98d6f366294fbd8cdbd59a6ed2039a` and experiment_id `1`\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "with mlflow.start_run(run_name=\"Basic KSVR Experiment\") as run:\n",
    "    ksvr_classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "    ksvr_classifier.fit(X_train, y_train)\n",
    "    ksvr_y_pred = ksvr_classifier.predict(X_test)\n",
    "\n",
    "    ksvr_cm = confusion_matrix(y_test, ksvr_y_pred)\n",
    "    print(ksvr_cm)\n",
    "    ksvr_score = accuracy_score(y_test, ksvr_y_pred)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(ksvr_classifier, \"KSVR-model\")\n",
    "\n",
    "    # Create metrics\n",
    "    print(f\"score: {ksvr_score}\")\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"score\", ksvr_score)\n",
    "\n",
    "    runID = run.info.run_uuid\n",
    "    experimentID = run.info.experiment_id\n",
    "\n",
    "    print(f\"Inside MLflow Run with run_id `{runID}` and experiment_id `{experimentID}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 10)                262830    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 262,951\n",
      "Trainable params: 262,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "               optimizer='adam', \n",
    "               metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                     epochs=100,\n",
    "                     verbose=False,\n",
    "                     validation_data=(X_test, y_test),\n",
    "                     batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.1685\n",
      "Testing Accuracy:  0.1885\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
